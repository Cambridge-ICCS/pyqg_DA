{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:  Logger initialized\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import importlib\n",
    "from matplotlib import pyplot as plt\n",
    "import DA_core as DA\n",
    "from glob import glob\n",
    "import torch.utils.data as Data\n",
    "from torch import optim\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "import ML_core as ML\n",
    "from numpy.random import default_rng\n",
    "import os\n",
    "\n",
    "rng = default_rng()\n",
    "DA.read_data_dir='/scratch/cimes/feiyul/PyQG/data/training'\n",
    "DA.save_data_dir='/scratch/cimes/feiyul/PyQG/data/training'\n",
    "\n",
    "data_dir='/scratch/cimes/feiyul/PyQG/data'\n",
    "# data_dir='/net2/fnl/PyQG/data'\n",
    "B_ens_kws={'cmap':'bwr','levels':np.linspace(-2.5E-11,2.5E-11,26),'extend':'both'}\n",
    "B_ens_kws1={'cmap':'bwr','levels':np.linspace(-0.25E-11,0.25E-11,26),'extend':'both'}\n",
    "q_kws={'cmap':'bwr','levels':np.linspace(-3.4E-5,3.4E-5,18),'extend':'both'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ML_core' from '/home/feiyul/PyQG/pyqg_experiments/examples/DA/ML_core.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2304"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('nvidia-smi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnKF_Nx64_from_Nx128_ens1280_freq10_relax0.45_R100_nobs50_50_err1E-5_5E-7\n"
     ]
    }
   ],
   "source": [
    "DA_paras={'nens':1280,\n",
    "          'DA_method':'EnKF',\n",
    "          'Nx_DA':64,\n",
    "          'Nx_truth':128,\n",
    "          'obs_freq':10,\n",
    "          'obs_err':[1,-5,5,-7],\n",
    "          'DA_freq':10,\n",
    "          'save_B':False,\n",
    "          'nobs':[50,50],\n",
    "          'R_W':100,\n",
    "          'inflate':[1,0.45]}\n",
    "DA_exp=DA.DA_exp(**DA_paras)\n",
    "print(DA_exp.file_name())\n",
    "# obs_ds=DA_exp.read_obs()\n",
    "in_ch=[0,1]\n",
    "out_ch=[0,1,2]\n",
    "\n",
    "DA_paras1={'nens':320,\n",
    "          'DA_method':'EnKF',\n",
    "          'Nx_DA':64,\n",
    "          'Nx_truth':128,\n",
    "          'obs_freq':10,\n",
    "          'obs_err':[1,-6,2,-8],\n",
    "          'DA_freq':10,\n",
    "          'save_B':False,\n",
    "          'nobs':[100,0],\n",
    "          'R_W':100,\n",
    "          'inflate':[1,0.55]}\n",
    "DA_exp1=DA.DA_exp(**DA_paras1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/cimes/feiyul/PyQG/data/training/EnKF/EnsMean_EnKF_Nx64_from_Nx128_ens1280_freq10_relax0.45_R100_nobs50_50_err1E-5_5E-7.nc\n",
      "(3650, 2, 64, 64)\n",
      "(365, 2, 64, 64, 2, 27, 27)\n",
      "slice(369, 3650, 10) slice(36, 365, None)\n"
     ]
    }
   ],
   "source": [
    "mean_ds=DA_exp.read_mean().load()\n",
    "print(mean_ds.q.shape)\n",
    "# if DA_exp.nens>1:  \n",
    "#     std_ds=DA_exp.read_std()\n",
    "\n",
    "# B_ens_ds=xr.open_mfdataset(['{}/{}/B_ens_day{:04d}.nc'.format(data_dir,DA_exp.file_name(),day) for day in np.arange(9,3650,10)])\n",
    "B_ens_ds=xr.open_dataset('{}/training/{}/B_ens.nc'.format(data_dir,DA_exp.file_name()))\n",
    "print(B_ens_ds.B_ens.shape)\n",
    "\n",
    "# ml_std_ds=xr.open_dataset('./ML/{0}/std_{0}.nc'.format(DA_exp.file_name()))\n",
    "# print(ml_std_ds)\n",
    "\n",
    "B_R=int((len(B_ens_ds.x_d)-1)/2)\n",
    "B_size=24\n",
    "B_start=1\n",
    "\n",
    "DA_days=slice(369,3650,DA_exp.DA_freq)\n",
    "DA_it=slice(int((DA_days.start-DA_exp.DA_freq+1)/DA_exp.DA_freq),int((DA_days.stop-DA_exp.DA_freq+1)/DA_exp.DA_freq)+1)\n",
    "print(DA_days,DA_it)\n",
    "i_x=slice(0,DA_exp.Nx_DA)\n",
    "i_y=slice(0,DA_exp.Nx_DA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(329, 2, 64, 64, 2, 27, 27)\n",
      "(329, 2, 64, 64)\n",
      "1347584\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ml_std_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/feiyul/PyQG/pyqg_experiments/examples/DA/B_UNet.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bstellar-vis/home/feiyul/PyQG/pyqg_experiments/examples/DA/B_UNet.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m rngs\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39marange(B_total)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bstellar-vis/home/feiyul/PyQG/pyqg_experiments/examples/DA/B_UNet.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m partition\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m:rngs[\u001b[39m0\u001b[39m:n_train],\u001b[39m'\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m'\u001b[39m:rngs[n_train:]}\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bstellar-vis/home/feiyul/PyQG/pyqg_experiments/examples/DA/B_UNet.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m train_ds\u001b[39m=\u001b[39mML\u001b[39m.\u001b[39mDataset(mean_ds\u001b[39m.\u001b[39mq\u001b[39m.\u001b[39misel(time\u001b[39m=\u001b[39mDA_days),DA_exp\u001b[39m.\u001b[39mNx_DA,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bstellar-vis/home/feiyul/PyQG/pyqg_experiments/examples/DA/B_UNet.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m                     B_ens_ds\u001b[39m.\u001b[39mB_ens\u001b[39m.\u001b[39misel(time\u001b[39m=\u001b[39mDA_it,y\u001b[39m=\u001b[39mi_y,x\u001b[39m=\u001b[39mi_x),\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bstellar-vis/home/feiyul/PyQG/pyqg_experiments/examples/DA/B_UNet.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m                     partition[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m],ml_std_ds\u001b[39m.\u001b[39mq_std\u001b[39m.\u001b[39mdata,ml_std_ds\u001b[39m.\u001b[39mB_std\u001b[39m.\u001b[39mdata,in_ch,out_ch,B_size\u001b[39m=\u001b[39mB_size,B_start\u001b[39m=\u001b[39mB_start)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bstellar-vis/home/feiyul/PyQG/pyqg_experiments/examples/DA/B_UNet.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m valid_ds\u001b[39m=\u001b[39mML\u001b[39m.\u001b[39mDataset(mean_ds\u001b[39m.\u001b[39mq\u001b[39m.\u001b[39misel(time\u001b[39m=\u001b[39mDA_days),DA_exp\u001b[39m.\u001b[39mNx_DA,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bstellar-vis/home/feiyul/PyQG/pyqg_experiments/examples/DA/B_UNet.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m                     B_ens_ds\u001b[39m.\u001b[39mB_ens\u001b[39m.\u001b[39misel(time\u001b[39m=\u001b[39mDA_it,y\u001b[39m=\u001b[39mi_y,x\u001b[39m=\u001b[39mi_x),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bstellar-vis/home/feiyul/PyQG/pyqg_experiments/examples/DA/B_UNet.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m                     partition[\u001b[39m'\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m'\u001b[39m],ml_std_ds\u001b[39m.\u001b[39mq_std\u001b[39m.\u001b[39mdata,ml_std_ds\u001b[39m.\u001b[39mB_std\u001b[39m.\u001b[39mdata,in_ch,out_ch,B_size\u001b[39m=\u001b[39mB_size,B_start\u001b[39m=\u001b[39mB_start)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bstellar-vis/home/feiyul/PyQG/pyqg_experiments/examples/DA/B_UNet.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m params \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m16\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mnum_workers\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m1\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mshuffle\u001b[39m\u001b[39m'\u001b[39m:\u001b[39mTrue\u001b[39;00m}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ml_std_ds' is not defined"
     ]
    }
   ],
   "source": [
    "B_shape=B_ens_ds.B_ens.isel(time=DA_it,y=i_y,x=i_x).shape\n",
    "print(B_shape)\n",
    "print(mean_ds.q.isel(time=DA_days).shape)\n",
    "B_nt=B_shape[0]\n",
    "B_ny=B_shape[2]\n",
    "B_nx=B_shape[3]\n",
    "B_total=B_nt*B_ny*B_nx\n",
    "print(B_total)\n",
    "n_train=int(B_total*0.8)\n",
    "# rngs=rng.permutation(B_total)\n",
    "rngs=np.arange(B_total)\n",
    "partition={'train':rngs[0:n_train],'valid':rngs[n_train:]}\n",
    "        \n",
    "train_ds=ML.Dataset(mean_ds.q.isel(time=DA_days),DA_exp.Nx_DA,\n",
    "                    B_ens_ds.B_ens.isel(time=DA_it,y=i_y,x=i_x),\n",
    "                    partition['train'],ml_std_ds.q_std.data,ml_std_ds.B_std.data,in_ch,out_ch,B_size=B_size,B_start=B_start)\n",
    "valid_ds=ML.Dataset(mean_ds.q.isel(time=DA_days),DA_exp.Nx_DA,\n",
    "                    B_ens_ds.B_ens.isel(time=DA_it,y=i_y,x=i_x),\n",
    "                    partition['valid'],ml_std_ds.q_std.data,ml_std_ds.B_std.data,in_ch,out_ch,B_size=B_size,B_start=B_start)\n",
    "\n",
    "params = {'batch_size':16,'num_workers':1,'shuffle':True}\n",
    "training_generator = torch.utils.data.DataLoader(train_ds, **params)\n",
    "validation_generator = torch.utils.data.DataLoader(valid_ds, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.84226755e-12 1.49484862e-13]\n",
      " [1.49484862e-13 3.69689238e-15]]\n",
      "[[6.64853917e-06]\n",
      " [1.22305091e-07]]\n"
     ]
    }
   ],
   "source": [
    "B_std=np.empty((2,2))\n",
    "B_std[0,0]=np.std(B_ens_ds.B_ens.isel(time=DA_it,lev=0,lev_d=0))\n",
    "B_std[0,1]=np.std(B_ens_ds.B_ens.isel(time=DA_it,lev=0,lev_d=1))\n",
    "B_std[1,0]=B_std[0,1]\n",
    "B_std[1,1]=np.std(B_ens_ds.B_ens.isel(time=DA_it,lev=1,lev_d=1))\n",
    "print(B_std)\n",
    "\n",
    "q_std=np.zeros((2,1))\n",
    "q_std[0]=np.std(mean_ds.q.isel(time=DA_days,lev=0))\n",
    "q_std[1]=np.std(mean_ds.q.isel(time=DA_days,lev=1))\n",
    "print(q_std)\n",
    "\n",
    "B_da=xr.DataArray(B_std,coords=[mean_ds.lev,mean_ds.lev])\n",
    "q_da=xr.DataArray(q_std.squeeze(),coords=[mean_ds.lev])\n",
    "std_ds=xr.Dataset({'B_std':B_da,'q_std':q_da})\n",
    "std_ds.to_netcdf('./ML/{0}/std_{0}.nc'.format(DA_exp.file_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 16, 16]             304\n",
      "              ReLU-2           [-1, 16, 16, 16]               0\n",
      "            Conv2d-3           [-1, 16, 16, 16]           2,320\n",
      "              ReLU-4           [-1, 16, 16, 16]               0\n",
      "         MaxPool2d-5             [-1, 16, 8, 8]               0\n",
      "            Conv2d-6             [-1, 32, 8, 8]           4,640\n",
      "              ReLU-7             [-1, 32, 8, 8]               0\n",
      "            Conv2d-8             [-1, 32, 8, 8]           9,248\n",
      "              ReLU-9             [-1, 32, 8, 8]               0\n",
      "        MaxPool2d-10             [-1, 32, 4, 4]               0\n",
      "           Conv2d-11             [-1, 64, 4, 4]          18,496\n",
      "             ReLU-12             [-1, 64, 4, 4]               0\n",
      "           Conv2d-13             [-1, 64, 4, 4]          36,928\n",
      "             ReLU-14             [-1, 64, 4, 4]               0\n",
      "        MaxPool2d-15             [-1, 64, 2, 2]               0\n",
      "           Conv2d-16            [-1, 128, 2, 2]          73,856\n",
      "             ReLU-17            [-1, 128, 2, 2]               0\n",
      "           Conv2d-18            [-1, 128, 2, 2]         147,584\n",
      "             ReLU-19            [-1, 128, 2, 2]               0\n",
      "  ConvTranspose2d-20             [-1, 64, 4, 4]          32,832\n",
      "           Conv2d-21             [-1, 64, 4, 4]          73,792\n",
      "             ReLU-22             [-1, 64, 4, 4]               0\n",
      "           Conv2d-23             [-1, 64, 4, 4]          36,928\n",
      "             ReLU-24             [-1, 64, 4, 4]               0\n",
      "  ConvTranspose2d-25             [-1, 32, 8, 8]           8,224\n",
      "           Conv2d-26             [-1, 32, 8, 8]          18,464\n",
      "             ReLU-27             [-1, 32, 8, 8]               0\n",
      "           Conv2d-28             [-1, 32, 8, 8]           9,248\n",
      "             ReLU-29             [-1, 32, 8, 8]               0\n",
      "  ConvTranspose2d-30           [-1, 16, 16, 16]           2,064\n",
      "           Conv2d-31           [-1, 16, 16, 16]           4,624\n",
      "             ReLU-32           [-1, 16, 16, 16]               0\n",
      "           Conv2d-33           [-1, 16, 16, 16]           2,320\n",
      "             ReLU-34           [-1, 16, 16, 16]               0\n",
      "           Conv2d-35            [-1, 3, 16, 16]              51\n",
      "================================================================\n",
      "Total params: 481,923\n",
      "Trainable params: 481,923\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.53\n",
      "Params size (MB): 1.84\n",
      "Estimated Total Size (MB): 2.37\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model=ML.Unet(in_ch=len(in_ch),out_ch=len(out_ch))\n",
    "model=model.to(device)\n",
    "print(device)\n",
    "\n",
    "# check keras-like model summary using torchsummary\n",
    "summary(model, input_size=(len(in_ch),train_ds.B_size,train_ds.B_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss() # MSE loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/feiyul/PyQG/pyqg_experiments/examples/DA/B_UNet.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bstellar-amd/home/feiyul/PyQG/pyqg_experiments/examples/DA/B_UNet.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# time0 = time()  \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bstellar-amd/home/feiyul/PyQG/pyqg_experiments/examples/DA/B_UNet.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start_epoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, n_epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bstellar-amd/home/feiyul/PyQG/pyqg_experiments/examples/DA/B_UNet.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     train_loss\u001b[39m.\u001b[39mappend(ML\u001b[39m.\u001b[39;49mtrain_model(model,criterion,training_generator,optimizer,device))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bstellar-amd/home/feiyul/PyQG/pyqg_experiments/examples/DA/B_UNet.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# validation_loss.append(ML.test_model(model,criterion,validation_generator,optimizer,device))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bstellar-amd/home/feiyul/PyQG/pyqg_experiments/examples/DA/B_UNet.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mstate_dict(), \u001b[39m'\u001b[39m\u001b[39m./ML/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/unet_epoch\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_in\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_out\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_B\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\\\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bstellar-amd/home/feiyul/PyQG/pyqg_experiments/examples/DA/B_UNet.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m         \u001b[39mformat\u001b[39m(DA_exp\u001b[39m.\u001b[39mfile_name(),epoch,\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mmap\u001b[39m(\u001b[39mstr\u001b[39m,in_ch)),\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mmap\u001b[39m(\u001b[39mstr\u001b[39m,out_ch)),B_size,DA_exp\u001b[39m.\u001b[39mfile_name()))\n",
      "File \u001b[0;32m~/PyQG/pyqg_experiments/examples/DA/ML_core.py:154\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(net, criterion, trainloader, optimizer, device)\u001b[0m\n\u001b[1;32m    152\u001b[0m loss \u001b[39m=\u001b[39m criterion(prediction, b_y)   \u001b[39m# Calculating loss \u001b[39;00m\n\u001b[1;32m    153\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()  \u001b[39m# clear gradients for next train\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()  \u001b[39m# backpropagation, compute gradients\u001b[39;00m\n\u001b[1;32m    155\u001b[0m optimizer\u001b[39m.\u001b[39mstep()  \u001b[39m# apply gradients to update weights\u001b[39;00m\n\u001b[1;32m    156\u001b[0m test_loss \u001b[39m=\u001b[39m test_loss \u001b[39m+\u001b[39m loss \u001b[39m# Keep track of the loss for convenience \u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pyqg/lib/python3.10/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/.conda/envs/pyqg/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model=model.double()\n",
    "n_epochs = 30 #Number of epocs\n",
    "validation_loss = list()\n",
    "train_loss = list()\n",
    "start_epoch=0\n",
    "if start_epoch>0:\n",
    "    model_file='./ML/unet_epoch{}_in{}_out{}_B{}_{}.pt'.format(start_epoch,''.join(map(str,in_ch)),''.join(map(str,out_ch)),B_size,DA_exp.file_name())\n",
    "    print(model_file)\n",
    "    model.load_state_dict(torch.load(model_file,map_location=torch.device('cpu')))\n",
    "# time0 = time()  \n",
    "for epoch in range(start_epoch+1, n_epochs + 1):\n",
    "    train_loss.append(ML.train_model(model,criterion,training_generator,optimizer,device))\n",
    "    # validation_loss.append(ML.test_model(model,criterion,validation_generator,optimizer,device))\n",
    "    torch.save(model.state_dict(), './ML/{}/unet_epoch{}_in{}_out{}_B{}_{}.pt'.\\\n",
    "        format(DA_exp.file_name(),epoch,''.join(map(str,in_ch)),''.join(map(str,out_ch)),B_size,DA_exp.file_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss,'b', label='training loss');\n",
    "plt.plot(validation_loss,'r', label='validation loss');\n",
    "\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pyqg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "6973bb065886c44b729be95666fc7914cdffcda5c95a8d198f96362135dd92cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
